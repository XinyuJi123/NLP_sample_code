{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e09cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\78234\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\78234\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#please make sure you have the package: pip install nameparser\n",
    "#current numpy version is 1.21\n",
    "import os\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nameparser.parser import HumanName\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import glob\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class NLP:\n",
    "    def __init__(self,write=True):\n",
    "        self.w=write\n",
    "        \n",
    "    def get_article_titles(self):\n",
    "        file_list = glob.glob(\"*.txt\") \n",
    "        fnames = []\n",
    "        for fname in file_list:\n",
    "            fname = fname.split('_')[0]\n",
    "            fnames.append(fname)\n",
    "        with open ('article_titles.json', 'w') as output_title:\n",
    "            output_title.write(json.dumps(fnames))\n",
    "    \n",
    "    def get_researcher_names(self):\n",
    "        person_articles = []\n",
    "        for article in glob.glob('./*.txt'):\n",
    "            article = open(article, 'r',encoding='utf-8')\n",
    "            # read all text\n",
    "            text = article.read()\n",
    "            t000=datetime.now()\n",
    "            #Depending on data structure and its cleanliness, we might need articles = articles.drop(columns=['xx', 'xx', 'xx'], axis=1)\n",
    "        \n",
    "            #From now on the sample code will extract researcher names from main text,which as I was told has already been extracted nicely.\n",
    "            #Therefore,I will focus on the data cleaning on main text.\n",
    "            \n",
    "            # Remove punctuation\n",
    "            text = re.sub('[,\\.!?]', '', text)\n",
    "            tokens = nltk.tokenize.word_tokenize(text)\n",
    "        \n",
    "            #Remove stopword (this step is not needed for name extraction. I put it here in case topic analysis is needed for later)\n",
    "            stop_words = stopwords.words('english')\n",
    "            tokens_without_stopwords = []\n",
    "            for word in tokens:\n",
    "                if word not in stop_words:\n",
    "                    tokens_without_stopwords.append(word) \n",
    "                    \n",
    "            #Part of sppech tag    \n",
    "            pos = nltk.pos_tag(tokens_without_stopwords)\n",
    "            #Named entity\n",
    "            ne = nltk.ne_chunk(pos, binary = False)\n",
    "            person = []\n",
    "            person_list = []\n",
    "            name = ''\n",
    "            for subtree in ne.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
    "                for leaf in subtree.leaves():\n",
    "                    person.append(leaf[0])\n",
    "                if len(person) > 1: #avoid grabbing lone surnames\n",
    "                    for part in person:\n",
    "                        name += part + ' '\n",
    "                    person_list.append(name)\n",
    "                    name = ''\n",
    "                person = []\n",
    "            person_articles.append(person_list)\n",
    "            \n",
    "        with open ('researcher_names_articles.json', 'w') as output_name:\n",
    "            output_name.write(json.dumps(person_articles))\n",
    "                \n",
    "                \n",
    "        t001=datetime.now()\n",
    "        dt00=t001-t000\n",
    "        print('Name Extraction is completed after '+str(dt00.total_seconds())+' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95782993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Extraction is completed after 0.094017 seconds\n"
     ]
    }
   ],
   "source": [
    "nlp=NLP(write=True)\n",
    "nlp.get_article_titles()\n",
    "nlp.get_researcher_names()\n",
    "#nlp.dictionary_titles_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38e80c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stephen Fried Johns Hopkins ',\n",
       " 'Charles University Czech Republic ',\n",
       " 'Human Frontier Science Program ',\n",
       " 'Anneliese M Faustino Johns Hopkins ',\n",
       " 'Mikhail Makarov Alma ',\n",
       " 'Sanchez Rocha Ivan Cherepashuk Robin Krystufek Klara Hlouchova Charles University ',\n",
       " 'Volha Dzmitruk Tatsiana Charnavets Michal Lebl Czech Academy Sciences ',\n",
       " 'Kosuke Fujishima Tokyo Institute Technology ']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles = []\n",
    "\n",
    "with open('article_titles.json') as output_title:\n",
    "    for title in output_title:\n",
    "        article_titles.append(json.loads(title))\n",
    "\n",
    "researcher_names = []\n",
    "        \n",
    "with open('researcher_names_articles.json') as output_name:\n",
    "    for name in output_name:\n",
    "        researcher_names.append(json.loads(name))\n",
    "                \n",
    "genders = []\n",
    "if os.path.exists('researcher_gender_articles.json'):\n",
    "    with open('researcher_gender_articles.json') as output_gender:\n",
    "        genders = json.load(output_gender)\n",
    "\n",
    "researcher_dict = {}\n",
    "for i in range(len(researcher_names[0])):\n",
    "    researcher_dict[article_titles[0][i]] = researcher_names[0][i]\n",
    "\n",
    "                \n",
    "def get_next_researcher():\n",
    "    return list(researcher_dict.values())[len(genders)]\n",
    "\n",
    "\n",
    "get_next_researcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7307476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "        \n",
       "function set_gender(gender){\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    kernel.execute(\"genders.append(\" + gender + \")\");\n",
       "    load_next_researcher();\n",
       "}\n",
       "\n",
       "function handle_output(out){\n",
       "    var res = out.content.data[\"text/plain\"];\n",
       "    $(\"div#researcher\").html(res);\n",
       "}\n",
       "        \n",
       "function load_next_researcher(){\n",
       "    var code_input = \"get_next_researcher()\";\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var callbacks = { 'iopub' : {'output' : handle_output}};\n",
       "    kernel.execute(code_input, callbacks, {silent:false});\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "        \n",
    "function set_gender(gender){\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    kernel.execute(\"genders.append(\" + gender + \")\");\n",
    "    load_next_researcher();\n",
    "}\n",
    "\n",
    "function handle_output(out){\n",
    "    var res = out.content.data[\"text/plain\"];\n",
    "    $(\"div#researcher\").html(res);\n",
    "}\n",
    "        \n",
    "function load_next_researcher(){\n",
    "    var code_input = \"get_next_researcher()\";\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    var callbacks = { 'iopub' : {'output' : handle_output}};\n",
    "    kernel.execute(code_input, callbacks, {silent:false});\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c96e21dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div name=\"researcherbox\">\n",
       "    Instructions: Click in textbox. Enter a 1 if the researcher is female, enter 0 otherwise. <br>\n",
       "Researcher Name: <div id=\"researcher\" value=\"text\"></div><br>\n",
       "<input type=researcher_names id=\"capture\"></input><br>\n",
       "</div>\n",
       "        \n",
       "<script>\n",
       "\n",
       "function set_gender(gender){\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    kernel.execute(\"genders.append(\" + gender + \")\");\n",
       "    load_next_researcher();\n",
       "}\n",
       "\n",
       "function handle_output(out){\n",
       "    var res = out.content.data[\"text/plain\"];\n",
       "    $(\"div#researcher\").html(res);\n",
       "}\n",
       "        \n",
       "function load_next_researcher(){\n",
       "    var code_input = \"get_next_researcher()\";\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var callbacks = { 'iopub' : {'output' : handle_output}};\n",
       "    kernel.execute(code_input, callbacks, {silent:false});\n",
       "}\n",
       "\n",
       "$(\"input#capture\").keypress(function(e) {\n",
       "if(e.which == 48) {\n",
       "    set_gender(0);\n",
       "    $(\"input#capture\").val(\"\");\n",
       "}else if (e.which == 49){\n",
       "    set_gender(1);\n",
       "    $(\"input#capture\").val(\"\");\n",
       "  }\n",
       "});\n",
       "        \n",
       "load_next_researcher();\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<div name=\"researcherbox\">\n",
    "    Instructions: Click in textbox. Enter a 1 if the researcher is female, enter 0 otherwise. <br>\n",
    "Researcher Name: <div id=\"researcher\" value=\"text\"></div><br>\n",
    "<input type=researcher_names id=\"capture\"></input><br>\n",
    "</div>\n",
    "        \n",
    "<script>\n",
    "\n",
    "function set_gender(gender){\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    kernel.execute(\"genders.append(\" + gender + \")\");\n",
    "    load_next_researcher();\n",
    "}\n",
    "\n",
    "function handle_output(out){\n",
    "    var res = out.content.data[\"text/plain\"];\n",
    "    $(\"div#researcher\").html(res);\n",
    "}\n",
    "        \n",
    "function load_next_researcher(){\n",
    "    var code_input = \"get_next_researcher()\";\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    var callbacks = { 'iopub' : {'output' : handle_output}};\n",
    "    kernel.execute(code_input, callbacks, {silent:false});\n",
    "}\n",
    "\n",
    "$(\"input#capture\").keypress(function(e) {\n",
    "if(e.which == 48) {\n",
    "    set_gender(0);\n",
    "    $(\"input#capture\").val(\"\");\n",
    "}else if (e.which == 49){\n",
    "    set_gender(1);\n",
    "    $(\"input#capture\").val(\"\");\n",
    "  }\n",
    "});\n",
    "        \n",
    "load_next_researcher();\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74ce7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('researcher_genders.json', 'w') as output_gender:\n",
    "    json.dump(genders,output_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c3e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
